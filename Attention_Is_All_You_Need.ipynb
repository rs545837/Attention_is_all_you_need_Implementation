{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Q3UOG92xQoX0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "heads = 8\n",
        "d = 512\n",
        "dff = 2048\n",
        "N = 6\n",
        "p = 0.1\n",
        "\n",
        "src = torch.randint(0, 100, (1, 4))\n",
        "trg = torch.randint(0, 50, (1, 2))"
      ],
      "metadata": {
        "id": "yQj5z1iQQ1x7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "    \"Embedding layer with scaling and dropout\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        d : int,\n",
        "        vocab_size : int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, d)\n",
        "    def forward(self, x: Tensor):\n",
        "        return self.embedding(x)"
      ],
      "metadata": {
        "id": "p8ndISpTRL_M"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "e = Embedding(d, 100)\n",
        "e(src).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsnBVCSbSmch",
        "outputId": "76ad74de-11a3-41ba-a548-3f54c4e56cdc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PE(nn.Module):\n",
        "    \"Implement the Positional Encoding function with dropout. \"\n",
        "    def __init__(\n",
        "        self,\n",
        "        d: int,\n",
        "        p: int,\n",
        "        max_len = 100\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.pe = torch.zeros(max_len, d)\n",
        "        pos = torch.arange(0, max_len, 1).unsqueeze(1)\n",
        "        div = torch.pow(10_000, 2 * torch.arange(0, d, 2) / d)\n",
        "        self.pe[:, 0::2] = torch.sin(pos / div)\n",
        "        self.pe[:, 1::2] = torch.cos(pos / div)\n",
        "\n",
        "        self.dropout = nn.Dropout(p)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.dropout(x + self.pe[:x.shape[1]])"
      ],
      "metadata": {
        "id": "BdUj5RnTSsE6"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pe = PE(d, p)\n",
        "pe(e(src)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E7GJm0ZVTOIR",
        "outputId": "97b43995-4202-4071-8161-89e1f38f83b8"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "    \"Multi head self-attention sub-layer followed by Add&Norm layer.\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        heads : int,\n",
        "        d : int\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.heads = heads\n",
        "        self.head_dim = d // heads\n",
        "        self.d = d\n",
        "\n",
        "        self.Q = nn.Linear(self.head_dim, self.head_dim)\n",
        "        self.K = nn.Linear(self.head_dim, self.head_dim)\n",
        "        self.V = nn.Linear(self.head_dim, self.head_dim)\n",
        "\n",
        "        self.linear = nn.Linear(self.d, self.d)\n",
        "        self.norm = nn.LayerNorm(d)\n",
        "\n",
        "    def forward(self, q: Tensor, k:Tensor, v: Tensor, mask=None) -> Tensor:\n",
        "        batch = q.shape[0]\n",
        "        q_len = q.shape[1]\n",
        "        k_len = k.shape[1]\n",
        "        v_len = v.shape[1]\n",
        "\n",
        "        Q = self.Q(q.reshape(batch, q_len, self.heads, self.head_dim))\n",
        "        K = self.K(k.reshape(batch, k_len, self.heads, self.head_dim))\n",
        "        V = self.V(v.reshape(batch, v_len, self.heads, self.head_dim))\n",
        "\n",
        "        QK = torch.einsum(\"bqhd, bkhd -> bhqk\", [Q, K])\n",
        "        scale = QK / math.sqrt(self.d)\n",
        "\n",
        "        if mask is not None:\n",
        "            scale = scale.masked_fill(mask == 0, float(\"-inf\"))\n",
        "\n",
        "        softmax = F.softmax(scale, dim=3)\n",
        "        output = torch.einsum(\"bhqk, bchd -> bqhd\", [softmax, V])\n",
        "        concat = output.reshape(batch, q_len, self.d)\n",
        "        linear = self.linear(concat)\n",
        "        addnorm = self.norm(linear + q)\n",
        "\n",
        "        return addnorm\n"
      ],
      "metadata": {
        "id": "EUFTt7mITVSY"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = SelfAttention(heads, d)\n",
        "x = pe(e(src))\n",
        "s(x, x, x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eKYhDc-Tzhk",
        "outputId": "bed26c12-7a9b-4c2b-f9cc-50919824bfee"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    \"Position-wise fully connected feed-forward network with 2 linear transformation, where first is followed by ReLU activation with Add&Norm operation\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        d : int,\n",
        "        dff : int\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.Linear(d, dff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(dff, d)\n",
        "        )\n",
        "        self.norm = nn.LayerNorm(d)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.norm(x + self.ff(x))\n",
        ""
      ],
      "metadata": {
        "id": "87cxfAsOT-CM"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = FeedForward(d, dff)\n",
        "x = s(x, x, x)\n",
        "f(x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSstMwabUfZ8",
        "outputId": "949a9bdc-2e43-4a78-f863-bf10b05a913d"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \"Encoder layer with two sub-layers multi-head attention and position-wise fully connected feed-forward network.\"\n",
        "    def __init__(\n",
        "       self,\n",
        "       head : int,\n",
        "       d : int,\n",
        "       dff : int\n",
        "     ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attention = SelfAttention(heads, d)\n",
        "        self.ff = FeedForward(d, dff)\n",
        "\n",
        "    def forward(self, q: Tensor, k: Tensor, v: Tensor) -> Tensor:\n",
        "        return self.ff(self.attention(q, k, v))"
      ],
      "metadata": {
        "id": "cZK8SnmFUlBh"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = EncoderLayer(heads, d , dff)\n",
        "x = pe(e(src))\n",
        "enc(x, x, x).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEidqipaWRK7",
        "outputId": "df4c8d65-41ed-4fde-d9d1-1a6b24ef513e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 4, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \"Decoder Layer with three sub-layers, two multi-head attention mecahnisms and position-wise fully connected feed-forward network on the top\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        heads : int,\n",
        "        d : int,\n",
        "        dff : int\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.masked_attention = SelfAttention(heads, d)\n",
        "        self.enc_layer = EncoderLayer(heads, d, dff)\n",
        "\n",
        "    def forward(self, x: Tensor, k: Tensor, v: Tensor, trg_mask: Tensor) -> Tensor:\n",
        "        q = self.masked_attention(x, x, x, trg_mask)\n",
        "        return self.enc_layer(q, k, v)"
      ],
      "metadata": {
        "id": "4doKt9pxWZQq"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    \"Encoder-Decoder architecture without Positional Encoding nor Embeddings\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        heads : int,\n",
        "        d : int,\n",
        "        dff : int,\n",
        "        N : int\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        self.enc_layer = nn.ModuleList([EncoderLayer(heads, d, dff) for _ in range(N)])\n",
        "        self.dec_layer = nn.ModuleList([DecoderLayer(heads, d, dff) for _ in range(N)])\n",
        "\n",
        "    def forward(self, src: Tensor, trg: Tensor) -> Tensor:\n",
        "        for enc in self.enc_layer:\n",
        "            src = enc(src, src, src)\n",
        "\n",
        "        for dec in self.dec_layer:\n",
        "            trg = dec(trg, src, src, self._make_mask(trg))\n",
        "\n",
        "        return trg\n",
        "\n",
        "    def _make_mask(self, trg):\n",
        "        #trg shape: [1, 4, 512]\n",
        "        batch, trg_len, _ = trg.shape\n",
        "        mask = torch.tril(torch.ones(trg_len, trg_len))\n",
        "\n",
        "        return mask.reshape(batch, 1, trg_len, trg_len)"
      ],
      "metadata": {
        "id": "XCrrw84oVUHE"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encdec = EncoderDecoder(heads, d, dff, N)\n",
        "s = pe(e(src))\n",
        "t = pe(e(trg))\n",
        "encdec(s, t).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwPFKcEuf9_X",
        "outputId": "fa50de64-a107-4f1b-c00e-e809bbd08098"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Classifier(nn.Module):\n",
        "    \"The last shape of transformer architecture wehre the ouput of decoder is passed through linear layer\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        d : int,\n",
        "        trg_vocab_size : int\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(d, trg_vocab_size)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        return self.linear(x)"
      ],
      "metadata": {
        "id": "F2pW1rQIgXCp"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = Classifier(d, 50)\n",
        "c(encdec(s,t)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcWTGEBNhv2O",
        "outputId": "e3ba2081-2631-442a-9bbd-4f6d051ecdc8"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        d : int,\n",
        "        heads : int,\n",
        "        dff : int,\n",
        "        N : int,\n",
        "        src_vocab_size : int,\n",
        "        trg_vocab_size : int,\n",
        "        p : int\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.encdec = EncoderDecoder(heads, d, dff, N)\n",
        "        self.pe = PE(d, p)\n",
        "        self.src_embeddings = Embedding(d, src_vocab_size)\n",
        "        self.trg_embeddings = Embedding(d, trg_vocab_size)\n",
        "        self.classifier = Classifier(d, trg_vocab_size)\n",
        "\n",
        "    def forward(self, src: Tensor, trg: Tensor) -> Tensor:\n",
        "        src = self.pe(self.src_embeddings(src))\n",
        "        trg = self.pe(self.trg_embeddings(trg))\n",
        "        output = self.encdec(src, trg)\n",
        "        return self.classifier(output)"
      ],
      "metadata": {
        "id": "2ysGBPvGh1mR"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = Transformer(\n",
        "    d = d,\n",
        "    heads = heads,\n",
        "    dff = dff,\n",
        "    N = N,\n",
        "    src_vocab_size = 100,\n",
        "    trg_vocab_size = 50,\n",
        "    p = p\n",
        ")\n",
        "\n",
        "t(src, trg).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqkmbVJBjFdZ",
        "outputId": "a3e5ebf4-9628-4c69-e34e-41650252abf5"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 50])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4rFI-XDDjcWx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}